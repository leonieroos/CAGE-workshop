{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Introduction into CAGE data\"\noutput:\n  html_notebook: default\n  df_print: paged\nbibliography: cage-ws.bib\n---\n\n\n\nbla bla bla\n\n\nblaaa\n\n\n# Differential Gene Expression\nCAGE data can also be used to assess expression of the cTSSs. Here, we will use the R-package DESeq2 [@love_moderated_2014]. Originated for RNA-seq data but can also handle similar data from other assaya types (such as CAGE data). The vignette and reference manual can be displayed by running the code below or can be found here [DESeq2](https://bioconductor.org/packages/release/bioc/html/DESeq2.html). \n\n```{r}\nbrowseVignettes(\"DESeq2\")\n```\n\n## Summary and goals of this practical\n<br>\n_CAGEr_\n\n* Prepare the right data format from CAGE data for DESEQ2\n* Export the data from CAGEr\n\n_DESeq2_\n\n* Normalise the data\n* Differential expression\n\n_Follow up_\n\n* Gene annotation\n* Gene ontology\n\n\n## 1 Exporting data from a CAGEset object\n### Creating a count table input for DESeq2\n<br>\nWe have worked until now with the two samples. However, for a differential expression analysis you will need more samples (replicates and/or more of the same condition). To this end, we'll include two more samples to the mix to follow the more standard work-flow and generate *p*-values. The two additional samples are again from the same R package (ZebrafishDevelopmentalCAGE). The analysis will be on early stage expression vs later stage expression: zf_64cells and zf_512cells vs zf_prim6 and zf_prim20. \n\n[DESeq2](https://bioconductor.org/packages/release/bioc/html/DESeq2.html) accepts matrices of read counts as input and this is exactly what we will export from CAGEr. It expects count data in the form of a matrix of integer values. The value in the i-th row and the j-th column of the matrix tells how many reads can be assigned to each cTSS site i in sample j. The values in the matrix should be un-normalized counts of sequencing reads.\n\nConsensus site (row) | Sample 1 tpm | Sample 2 tpm | Sample 3 tpm | Sample 4 tpm  \n-------------  | ------------- | ------------- | ------------- | -------------\n1              | 0    | 1 | 44 | 60        \n2              | 4 | 10 | 6 | 9       \n\n> <small>!! \"The DESeq2 model internally corrects for library size, so transformed or normalized values such as counts scaled by library size should not be used as input\" </small>\n\nThe code below was run to produce the consensus clusters for the four samples as this would take to long to do on the day. The one important (different step) is shown below in the code. Don't run the code (today).\n\n```{r, eval=FALSE}\n# packages\nrequire(ZebrafishDevelopmentalCAGE)\nrequire(CAGEr)\n# load data\ndata(ZebrafishSamples)\nas.character(ZebrafishSamples$sample)\nmyCAGEset <- importPublicData(source = \"ZebrafishDevelopment\", dataset = \"ZebrafishCAGE\", \ngroup = \"development\", sample = as.character(ZebrafishSamples$sample[c(3:4,11:12)] ) )\n\n# CTSS tag count\nctss <- CTSStagCount(myCAGEset)\n\n#\n# To keep using the raw counts in all downstream steps, the normalizeTagCount function of CAGEr should be used with the method set to \"none\". Note that normalizeTagCount function has to be applied to CAGEset object before moving to next steps.\nnormalizeTagCount(myCAGEset, method = \"none\")\n#\n\n\n# Clustering of CTSS: low fidelity cTSSs are removed (each cluster with only one cTSS signal < 5).\nclusterCTSS(object = myCAGEset, threshold = 1, thresholdIsTpm = TRUE, \n            nrPassThreshold = 1, method = \"distclu\", maxDist = 20, \n            removeSingletons = TRUE, keepSingletonsAbove = 5)\n\n# cumulative distribution and quantile positions\ncumulativeCTSSdistribution(myCAGEset, clusters = \"tagClusters\")\nquantilePositions(myCAGEset, clusters = \"tagClusters\", qLow = 0.1, qUp = 0.9)\n\n# aggregate the clusters across the samples:\naggregateTagClusters(myCAGEset, tpmThreshold = 5, qLow = 0.1, qUp = 0.9, maxDist = 100)\nsave(myCAGEset, file = \"../Data/provided/AggregatedTagClus_0109_4Samples.RData\")\n```\n\n<br>\nTo be able to compare transcriptional activity across these samples, consensus clusters will be used for downstream analysis. This is provided to you in a .RData file. The following steps involve creating the count data table for each consensus cluster, merge it with the coordinates of the consensus, and to write a file with the output in the intermediate directory within the Data directory. \n\n```{r, message = FALSE}\n# package\nrequire(CAGEr)\n\n# load the data produced by the code above\nload(\"../Data/provided_data/AggregatedTagClus_0109_4Samples.RData\")\n\n# create count tpm matrix per consensus cluster for each sample\ncount.df <- data.frame(consensusClustersTpm(myCAGEset))\n\n# and the consensus coordinates (same order)\nconsensus.info <- consensusClusters(myCAGEset)\n\n# create identifiers to link back\nconsensus.info$cons_clus_id <- paste(\"cid_\",1:nrow(consensus.info), sep = \"\")\nrownames(count.df) <- consensus.info$cons_clus_id\n\n# save the combined info and count tpm as intermediate files \n# the order is the same so we can easily use cbind\ncount.consensus.info <- cbind(consensus.info[,-1], count.df)\nwrite.table(count.consensus.info, \"Data/intermediate_data/CountTable_Consensus_4Samples.txt\", col.names = TRUE, row.names = FALSE, sep = \"\\t\", quote = FALSE)\n\n# remove unnecessary files \nrm(myCAGEset, samples, consensus.info)\n```\n\n<br>\n\n## 2 DESeq2 Data Analysis\n<br>\nFirst, we will make a DESeqDataSet object from the count table and add the \"formula\" which is the design of the analysis downstream (a linear model: ~ condition). In this example we are only using the variable (early vs late), however, if you want to add covariates in the model (e.g. batch) these would be extra columns in info.df (see below) and given in the model like : ~ column name covariate + variable. So the variable will be the last in the model. \n\n```{r}\n# DESeq2 expects a matrix of count table:\ncount.matrix <- as.matrix(count.df) # if from previously saved file: as.matrix(count.consensus.info[,7:10])\nhead(count.matrix)\n```\n```{r}\n# the condition for the analysis in data.frame:\nsamples <- colnames(count.matrix)\ninfo.df <- data.frame(condition = factor(x = c(\"early\", \"early\", \"late\", \"late\"), levels = c(\"early\",\"late\")), row.names = samples)\n\n```\n\n<br>\nThe reason for specifying the levels of the factor is because by default, R will handle factor levels based on alphabetical order. It is good practice to get into, especially in analyses where it matters which level you want to compare against. Thus identifying correctly up- or down-regulated genes in this case.\n<br>\nThe first thing to do now is to create a DESeqDataSet object that stores the count matrix and design:\n\n```{r, message = FALSE}\nrequire(DESeq2)\ndds <- DESeqDataSetFromMatrix(countData = count.matrix, colData = info.df, design = ~ condition)\n```\n<br>\nLet's first do a simple heatmap to check how similar (or dissimilar) the four samples are on a genome-wide transcription level. For this we will use the transformed data as performed by DESeq2. It can do three different types of transformation and here we will use the function\n__rlog__, which stands for regularized log. It transforms the original count data to the log2 scale by fitting a model with a term for each sample and a prior distribution on the coefficients which is estimated from the data (See DESseq vignette for more info). \n\n```{r}\n# package\nrequire(RColorBrewer)\nrequire(pheatmap)\n# Extracting transformed values:\nrld <- rlog(dds, blind=FALSE)\n# heatmap\nsampleDists <- dist(t(assay(rld)))\nsampleDistMatrix <- as.matrix(sampleDists)\n\nrownames(sampleDistMatrix) <- rld$condition\ncolnames(sampleDistMatrix) <- NULL\n\ncolors <- colorRampPalette( rev(brewer.pal(9, \"Blues\")) )(255)\n\npheatmap(sampleDistMatrix, clustering_distance_rows=sampleDists,\n        clustering_distance_cols=sampleDists,col=colors)\n```\n\nIndeed, the samples are clustering according to the developmental time frame. There are more things you can do and check such as principal component analysis that are also described in the vignette.\n<br>\n<br>\nThe standard differential expression analysis steps are wrapped into a single function, __DESeq__. Results tables are generated using the function __results__, which extracts a results table with log2 fold changes, pvalues and adjusted pvalues. The text, condition treated vs untreated, tells you that the estimates are of the logarithmic fold change log2 (treated/untreated). \n\n```{r, message = FALSE}\n# the analysis\ndds <- DESeq(dds)\n# results\nres <- results(dds)\n```\n\n<br> \nNext, we want to know what are the lowest adjusted pvalues as these are of interest, which genes they represent, and gene ontology for patterns in the data.\n<br>\nFirst, let's reorder the results according to lowest p-value:\n```{r}\nresOrdered <- res[order(res$padj),]\nresOrdered\n```\nAn easy summary:\n```{r}\nsummary(res)\n```\n\nThe amount cTSS differentially expressed (padj < 0.05):\n```{r}\nsum(res$padj < 0.05, na.rm=TRUE)\n```\n\nSave the results in a table in the Intermediate directory:\n```{r}\n# First add the cons_clus_id for identification\nresOrdered$cons_clus_id <- resOrdered@rownames\n# Dataframe for downstream\nresult <- as.data.frame(resOrdered)\n# save as intermediate file\nwrite.table(result, \"../Data/intermediate_data/DiffExpression_Consensus_4Samples.txt\", col.names = TRUE, row.names = FALSE, quote = FALSE, sep = \"\\t\")\n# remove previous files\nrm(res, resOrdered)\n```\n\n<br>\n\n## 3 Gene annotation and Gene ontology\n<br>\nLet's start by having a txdb for our samples. The txdb was created with the code below and is in the provided data directory. \n\n```{r, eval = FALSE}\n# dan rerio v7\nrequire(GenomicFeatures)\nrequire(AnnotationDbi)\ntxdb <- makeTxDbFromUCSC(\"danRer7\", \"ensGene\")\nsaveDb(txdb, file = \"../Data/provided_data/txdb_DanRer7.sqlite\")\n```\n\nLoad in the the txdb:\n```{r}\nrequire(GenomicFeatures)\nrequire(AnnotationDbi)\ntxdb <- loadDb(\"..Data/provided_data/txdb_DanRer7.sqlite\")\n```\n\nLet's run through a few things first and build a function for later purposes. First defining \n```{r}\n# 5' UTR (500bp window around refgene TSS)\npromoters = trim(promoters(txdb, upstream=500, downstream=500))\n# 5 kb upstream - 500bp \nupstream = trim(flank(promoters, 5000))\n# exons\nexons <- exons(txdb)\n# introns\nintrons = intronsByTranscript(txdb)\n# genes\ngene = genes(txdb)\n\n\n```\n\n\n\n# References\n",
    "created" : 1482000439105.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "297565134",
    "id" : "99293C6D",
    "lastKnownWriteTime" : 1482000698,
    "last_content_update" : 1482000698649,
    "path" : "~/Documents/workshop/cage/scripts/CAGE-workshop-FullCode-v1.Rmd",
    "project_path" : "scripts/CAGE-workshop-FullCode-v1.Rmd",
    "properties" : {
        "chunk_output_type" : "inline"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}